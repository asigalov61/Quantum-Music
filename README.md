# Quantum-Music

## Quantization is all you need

***

### Quantization of music elements shows promising results when it comes to Music AI.


***

### Some info:

1) Part of the success of the OpenAI's MuseNet was in the accidental quantization of time. This allowed MuseNet model to learn to generate silent intervals and uneven tempos.
2) Quantizing pitches also shows interesting results as the NN learns how to manipulate pitches properly.
3) Other music elements such as duration and velocity can and should be quantized too. Unfortunately, this will dramatically increase the dataset size.

***

### Proposed solutions:

1) Tokenized Sparse Time Quantization
2) Tokenized Sparse Pitches Quantization
3) If possible and resultative, Full Tokenized Sparse Quantization


***

### Examples of proposed Music Quatization:

#### See full examples colab notebooks in the repo or click below...

[![Open In Colab][colab-badge]][colab-notebook]

[colab-notebook]: <https://colab.research.google.com/github/asigalov61/Quantum-Music/blob/main/Quantum_Music.ipynb>
[colab-badge]: <https://colab.research.google.com/assets/colab-badge.svg>

***

### Citation

```bibtex
@inproceedings{lev2021quantummusic,
    title       = {Quantum Music},
    author      = {Aleksandr Lev},
    booktitle   = {GitHub},
    year        = {2021},
}
```

***

### Project Los Angeles

### Tegridy Code 2021
