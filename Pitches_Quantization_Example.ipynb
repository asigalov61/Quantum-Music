{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SiTIpPjArIyr"
   },
   "source": [
    "# Optimus VIRTUOSO: Relative Global Attention Edition (ver. 1.0)\n",
    "\n",
    "## \"Music never allows falsehoods for even the deaf hear flat notes!\" ---OV\n",
    "\n",
    "***\n",
    "\n",
    "Powered by tegridy-tools TMIDIX Optimus Processors: https://github.com/asigalov61/tegridy-tools\n",
    "\n",
    "***\n",
    "\n",
    "Credit for GPT2-RGA code used in this colab goes out @ Sashmark97 https://github.com/Sashmark97/midigen and @ Damon Gwinn https://github.com/gwinndr/MusicTransformer-Pytorch\n",
    "\n",
    "***\n",
    "\n",
    "WARNING: This complete implementation is a functioning model of the Artificial Intelligence. Please excercise great humility, care, and respect. https://www.nscai.gov/\n",
    "\n",
    "***\n",
    "\n",
    "#### Project Los Angeles\n",
    "\n",
    "#### Tegridy Code 2021\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gOd93yV0sGd2"
   },
   "source": [
    "# (Setup Environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "lw-4aqV3sKQG"
   },
   "outputs": [],
   "source": [
    "#@title nvidia-smi gpu check\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "fX12Yquyuihc"
   },
   "outputs": [],
   "source": [
    "#@title Install all dependencies (run only once per session)\n",
    "\n",
    "!git clone https://github.com/asigalov61/tegridy-tools\n",
    "!pip install torch\n",
    "!pip install tqdm\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "z7n9vnKmug1J"
   },
   "outputs": [],
   "source": [
    "#@title Import all needed modules\n",
    "\n",
    "print('Loading needed modules. Please wait...')\n",
    "import os\n",
    "from datetime import datetime\n",
    "import secrets\n",
    "import copy\n",
    "import tqdm\n",
    "from tqdm import auto\n",
    "\n",
    "if not os.path.exists('/notebooks/Dataset'):\n",
    "    os.makedirs('/notebooks/Dataset')\n",
    "\n",
    "print('Loading TMIDIX module...')\n",
    "os.chdir('/notebooks/tegridy-tools/tegridy-tools')\n",
    "import TMIDIX\n",
    "\n",
    "os.chdir('/notebooks/tegridy-tools/tegridy-tools')\n",
    "from GPT2RGA import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from IPython.display import display, Javascript, HTML, Audio\n",
    "\n",
    "#from google.colab import output, drive\n",
    "\n",
    "os.chdir('/notebooks/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ObPxlEutsQBj"
   },
   "source": [
    "# (FROM SCRATCH) Download and process MIDI dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "snIZ3xKPsPgB"
   },
   "outputs": [],
   "source": [
    "#@title Download Endless Violin Carousel MIDI dataset (Recommended)\n",
    "\n",
    "#@markdown Piano Violin Duo\n",
    "\n",
    "#@markdown Works best stand-alone/as-is for the optimal results\n",
    "%cd /notebooks/Dataset/\n",
    "\n",
    "!wget 'https://github.com/asigalov61/Tegridy-MIDI-Dataset/raw/master/Endless-Violin-Carousel-CC-BY-NC-SA.zip'\n",
    "!unzip -j '/notebooks/Dataset/Endless-Violin-Carousel-CC-BY-NC-SA.zip'\n",
    "!rm '/notebooks/Dataset/Endless-Violin-Carousel-CC-BY-NC-SA.zip'\n",
    "\n",
    "%cd /notebooks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "on7sgKEP3Yc8"
   },
   "outputs": [],
   "source": [
    "#@title Process MIDIs to special MIDI dataset with Tegridy MIDI Processor\n",
    "\n",
    "#@markdown IMPORTANT NOTES:\n",
    "\n",
    "#@markdown 1) Best results are achieved with the single-track, single-channel, single-instrument MIDI 0 files with plain English names (avoid special or sys/foreign chars)\n",
    "\n",
    "#@markdown 2) MIDI Channel = -1 means all MIDI channels except the drums. MIDI Channel = 16 means all channels will be processed. Otherwise, only single indicated MIDI channel will be processed\n",
    "\n",
    "desired_dataset_name = \"Optimus-VIRTUOSO-Music-Dataset\" #@param {type:\"string\"}\n",
    "file_name_to_output_dataset_to = \"/notebooks/Optimus-VIRTUOSO-Music-Dataset\" #@param {type:\"string\"}\n",
    "desired_MIDI_channel_to_process = -1 #@param {type:\"slider\", min:-1, max:16, step:1}\n",
    "sorted_or_random_file_loading_order = True #@param {type:\"boolean\"}\n",
    "encode_velocities = True #@param {type:\"boolean\"}\n",
    "encode_MIDI_channels = True #@param {type:\"boolean\"}\n",
    "add_transposed_dataset_by_this_many_pitches = 0 #@param {type:\"slider\", min:-12, max:12, step:1}\n",
    "add_transposed_and_flipped_dataset = False #@param {type:\"boolean\"}\n",
    "chordify_input_MIDIs = False #@param {type:\"boolean\"}\n",
    "melody_conditioned_chords = False #@param {type:\"boolean\"}\n",
    "melody_pitch_baseline = 60 #@param {type:\"slider\", min:0, max:127, step:1}\n",
    "time_denominator = 1 #@param {type:\"slider\", min:1, max:50, step:1}\n",
    "transform_to_pitch = 0 #@param {type:\"slider\", min:0, max:127, step:1}\n",
    "perfect_timings = True #@param {type:\"boolean\"}\n",
    "MuseNet_encoding = True #@param {type:\"boolean\"}\n",
    "chars_encoding_offset = 0 #@param {type:\"number\"}\n",
    "\n",
    "print('TMIDI Optimus MIDI Processor')\n",
    "print('Starting up...')\n",
    "###########\n",
    "\n",
    "average_note_pitch = 0\n",
    "min_note = 127\n",
    "max_note = 0\n",
    "\n",
    "files_count = 0\n",
    "\n",
    "gfiles = 0\n",
    "\n",
    "chords_list_f = []\n",
    "melody_list_f = []\n",
    "\n",
    "chords_list = []\n",
    "chords_count = 0\n",
    "\n",
    "melody_chords = []\n",
    "melody_count = 0\n",
    "\n",
    "TXT_String = ''\n",
    "\n",
    "TXT = ''\n",
    "melody = []\n",
    "chords = []\n",
    "INTS_f = []\n",
    "###########\n",
    "\n",
    "print('Loading MIDI files...')\n",
    "print('This may take a while on a large dataset in particular.')\n",
    "\n",
    "dataset_addr = \"/notebooks/Dataset/\"\n",
    "os.chdir(dataset_addr)\n",
    "filez = list()\n",
    "for (dirpath, dirnames, filenames) in os.walk(dataset_addr):\n",
    "    filez += [os.path.join(dirpath, file) for file in filenames]\n",
    "print('=' * 70)\n",
    "\n",
    "if filez == []:\n",
    "  print('Could not find any MIDI files. Please check Dataset dir...')\n",
    "  print('=' * 70)\n",
    "\n",
    "if sorted_or_random_file_loading_order:\n",
    "  print('Sorting files...')\n",
    "  filez.sort()\n",
    "  print('Done!')\n",
    "  print('=' * 70)\n",
    "\n",
    "# Stamping the dataset info\n",
    "print('Stamping the dataset info...')\n",
    "\n",
    "TXT_String += 'DATASET=' + str(desired_dataset_name) + chr(10)\n",
    "TXT_String += 'CREATED_ON=' + str(datetime.now()).replace(' ', '-').replace(':', '-').replace('.', '-') + chr(10)\n",
    "\n",
    "TXT_String += 'CHARS_ENCODING_OFFSET=' + str(chars_encoding_offset) + chr(10)\n",
    "TXT_String += 'TIME_DENOMINATOR=' + str(time_denominator) + chr(10)\n",
    "TXT_String += 'TRANSFORM=' + str(transform_to_pitch) + chr(10)\n",
    "TXT_String += 'PERFECT_TIMINGS=' + str(perfect_timings) + chr(10)\n",
    "TXT_String += 'MUSENET_ENCODING=' + str(MuseNet_encoding) + chr(10)\n",
    "TXT_String += 'TRANSPOSED_BY=' + str(add_transposed_dataset_by_this_many_pitches) + chr(10)\n",
    "TXT_String += 'TRANSPOSED_AND_FLIPPED=' + str(add_transposed_and_flipped_dataset) + chr(10)\n",
    "\n",
    "TXT_String += 'LEGEND=STA-DUR-PTC'\n",
    "if encode_velocities:\n",
    "  TXT_String += '-VEL'\n",
    "if encode_MIDI_channels:\n",
    "  TXT_String += '-CHA'\n",
    "TXT_String += chr(10)\n",
    "\n",
    "print('Processing MIDI files. Please wait...')\n",
    "for f in tqdm(filez):\n",
    "  try:\n",
    "    fn = os.path.basename(f)\n",
    "    fn1 = fn.split('.')[0]\n",
    "\n",
    "    files_count += 1\n",
    "    TXT, melody, chords, bass_melody, karaokez, INTS, aux1, aux2 = TMIDIX.Optimus_MIDI_TXT_Processor(f, chordify_TXT=chordify_input_MIDIs, output_MIDI_channels=encode_MIDI_channels, char_offset=chars_encoding_offset, dataset_MIDI_events_time_denominator=time_denominator, output_velocity=encode_velocities, MIDI_channel=desired_MIDI_channel_to_process, MIDI_patch=range(0, 127), melody_conditioned_encoding=melody_conditioned_chords, melody_pitch_baseline=melody_pitch_baseline, perfect_timings=perfect_timings, musenet_encoding=MuseNet_encoding, transform=transform_to_pitch)\n",
    "    TXT_String += TXT\n",
    "    melody_list_f += melody\n",
    "    chords_list_f += chords\n",
    "    INTS_f.append(INTS)\n",
    "    gfiles += 1\n",
    "\n",
    "    if add_transposed_dataset_by_this_many_pitches != 0:\n",
    "\n",
    "      TXT, melody, chords, bass_melody, karaokez, INTS, aux1, aux2 = TMIDIX.Optimus_MIDI_TXT_Processor(f, chordify_TXT=chordify_input_MIDIs, output_MIDI_channels=encode_MIDI_channels, char_offset=chars_encoding_offset, dataset_MIDI_events_time_denominator=time_denominator, output_velocity=encode_velocities, MIDI_channel=desired_MIDI_channel_to_process, transpose_by=add_transposed_dataset_by_this_many_pitches, MIDI_patch=range(0, 127), melody_conditioned_encoding=melody_conditioned_chords, melody_pitch_baseline=melody_pitch_baseline, perfect_timings=perfect_timings, musenet_encoding=MuseNet_encoding, transform=transform_to_pitch)\n",
    "      TXT_String += TXT\n",
    "      melody_list_f += melody\n",
    "      chords_list_f += chords\n",
    "      INTS_f.append(INTS)\n",
    "      gfiles += 1\n",
    "\n",
    "    if add_transposed_and_flipped_dataset == True:\n",
    "\n",
    "      TXT, melody, chords, bass_melody, karaokez, INTS, aux1, aux2 = TMIDIX.Optimus_MIDI_TXT_Processor(f, chordify_TXT=chordify_input_MIDIs, output_MIDI_channels=encode_MIDI_channels, char_offset=chars_encoding_offset, dataset_MIDI_events_time_denominator=time_denominator, output_velocity=encode_velocities, MIDI_channel=desired_MIDI_channel_to_process, transpose_by=-12, MIDI_patch=range(0, 127), flip=True, melody_conditioned_encoding=melody_conditioned_chords, melody_pitch_baseline=melody_pitch_baseline, perfect_timings=perfect_timings, musenet_encoding=MuseNet_encoding, transform=transform_to_pitch)\n",
    "      TXT_String += TXT\n",
    "      melody_list_f += melody\n",
    "      chords_list_f += chords\n",
    "      INTS_f.append(INTS)\n",
    "      gfiles += 1\n",
    "\n",
    "  except KeyboardInterrupt:\n",
    "    print('Saving current progress and quitting...')\n",
    "    break  \n",
    "  \n",
    "  except:\n",
    "    print('Bad MIDI:', f)\n",
    "    continue\n",
    "\n",
    "TXT_String += 'TOTAL_SONGS_IN_DATASET=' + str(gfiles)\n",
    "\n",
    "try:\n",
    "  print('Task complete :)')\n",
    "  print('==================================================')\n",
    "  if add_transposed_dataset_by_this_many_pitches != 0:\n",
    "    print('NOTE: Transposed dataset was added per users request.')\n",
    "    print('==================================================')\n",
    "  if add_transposed_and_flipped_dataset == True:\n",
    "    print('NOTE: Flipped dataset was added per users request.')  \n",
    "    print('==================================================')\n",
    "  print('Number of processed dataset MIDI files:', files_count)\n",
    "  print('Number of MIDI chords recorded:', len(chords_list_f))\n",
    "  print('First chord event:', chords_list_f[0], 'Last chord event:', chords_list_f[-1]) \n",
    "  print('Number of recorded melody events:', len(melody_list_f))\n",
    "  print('First melody event:', melody_list_f[0], 'Last Melody event:', melody_list_f[-1])\n",
    "  print('Total number of MIDI events recorded:', len(chords_list_f) + len(melody_list_f))\n",
    "  print('==================================================')\n",
    "\n",
    "  # Writing dataset to TXT file\n",
    "  with open(file_name_to_output_dataset_to + '.txt', 'wb') as f:\n",
    "    f.write(TXT_String.encode('utf-8', 'replace'))\n",
    "    f.close\n",
    "\n",
    "  # Dataset\n",
    "  MusicDataset = [chords_list_f, melody_list_f, INTS_f]\n",
    "\n",
    "  # Writing dataset to pickle file\n",
    "  TMIDIX.Tegridy_Any_Pickle_File_Writer(MusicDataset, file_name_to_output_dataset_to)\n",
    "\n",
    "except:\n",
    "  print('=' * 70)\n",
    "  print('IO Error!')\n",
    "  print('Please check that Dataset dir is not empty/check other IO code.')\n",
    "  print('=' * 70)\n",
    "  print('Shutting down...')\n",
    "  print('=' * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SONG = []\n",
    "pe = chords_list_f[0]\n",
    "for c in chords_list_f:\n",
    "    #if c[4] > 60:\n",
    "    SONG.append(c)\n",
    "    pe = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "lT0TyqUnpxu_"
   },
   "outputs": [],
   "source": [
    "#@title Load processed INTs datasets\n",
    "number_of_batches = 16 #@param {type:\"slider\", min:2, max:32, step:2}\n",
    "n_workers = 6\n",
    "\n",
    "print('=' * 50)\n",
    "print('Prepping INTs datasets...')\n",
    "\n",
    "INTS_f1 = []\n",
    "\n",
    "pe = SONG[0]\n",
    "for S in SONG:\n",
    "    \n",
    "    INTS_f1.extend([0])\n",
    "    if abs(S[1]-pe[1]) != 0 and abs(S[1]-pe[1]) < 376:\n",
    "\n",
    "        INTS_f1.extend([abs(S[1]-pe[1])+10]) \n",
    "\n",
    "\n",
    "    o = S[4] // 12\n",
    "    t = S[4] % 12\n",
    "\n",
    "    for i in range(t+1):    \n",
    "                INTS_f1.extend([o])\n",
    "    \n",
    "    \n",
    "       \n",
    "    pe = S\n",
    "    \n",
    "train_data = []\n",
    "for i in INTS_f1:\n",
    "    train_data.append(i)\n",
    "\n",
    "val_dataset = train_data[:int(len(train_data) * 0.1)]\n",
    "test_dataset = train_data[:int(len(train_data) * 0.1)]\n",
    "\n",
    "train_list = train_data\n",
    "val_list = val_dataset\n",
    "test_list = []\n",
    "print('=' * 50)\n",
    "\n",
    "print('Processing INTs datasets...')\n",
    "train_dataset = EPianoDataset(train_list, max_seq, random_seq)\n",
    "val_dataset = EPianoDataset(val_list, max_seq)\n",
    "test_dataset = EPianoDataset(test_list, max_seq)\n",
    "print('=' * 50)\n",
    "\n",
    "print('Loading INTs datasets...')\n",
    "batch_size = number_of_batches\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=n_workers, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=n_workers)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=n_workers)\n",
    "print('=' * 50)\n",
    "\n",
    "print('Total INTs in the dataset', len(train_data))\n",
    "print('Total unique INTs in the dataset', len(set(train_data)))\n",
    "print('Max INT in the dataset', max(train_data))\n",
    "print('Min INT in the dataset', min(train_data))\n",
    "print('=' * 50)\n",
    "\n",
    "print('Checking datasets shapes...')\n",
    "print('=' * 50)\n",
    "\n",
    "print('Train loader')\n",
    "for x, tgt in train_loader:\n",
    "    print(f'X shape: {x.shape}')\n",
    "    print(f'Target shape: {tgt.shape}')\n",
    "    break\n",
    "print('=' * 50)\n",
    "\n",
    "print('Validation loader')\n",
    "for x, tgt in val_loader:\n",
    "    print(f'X shape: {x.shape}')\n",
    "    print(f'Target shape: {tgt.shape}')\n",
    "    break\n",
    "print('=' * 50)\n",
    "\n",
    "print('Test loader')\n",
    "for x, tgt in test_loader:\n",
    "    print(f'X shape: {x.shape}')\n",
    "    print(f'Target shape: {tgt.shape}')\n",
    "    break\n",
    "print('=' * 50)\n",
    "\n",
    "print('Done! Enjoy! :)')\n",
    "print('=' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the resulting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out = train_data[:85000]\n",
    "\n",
    "if len(out) != 0:\n",
    "  song = out\n",
    "  song_f = []\n",
    "  time = 0\n",
    "  octave = 0\n",
    "  tone = 0\n",
    "  pe = song[0]\n",
    "  for s in song:\n",
    "    \n",
    "    \n",
    "    if s > 0 and s < 10 and s != pe and pe < 10:\n",
    "\n",
    "        song_f.append(['note', time, 500, 0, (octave * 12) + tone, (octave * 10) + tone ])    \n",
    "        tone = 0\n",
    "        octave = s\n",
    "\n",
    "    if s > 9 and pe < 10 and pe >= 0:\n",
    "        song_f.append(['note', time, 500, 0, (octave * 12) + tone, (octave * 10) + tone ])\n",
    "        tone = 0\n",
    "\n",
    "        \n",
    "    if s > 9:\n",
    "        time += (s - 10)\n",
    "        tone = 0\n",
    "        \n",
    "    if s > 0 and s < 10:  \n",
    "       tone += 1\n",
    "       octave = s\n",
    "        \n",
    "\n",
    "        \n",
    "    pe = s\n",
    "\n",
    "  detailed_stats = TMIDIX.Tegridy_SONG_to_MIDI_Converter(song_f,\n",
    "                                                        output_signature = 'TEST',  \n",
    "                                                        output_file_name = '/notebooks/TEST', \n",
    "                                                        track_name='TEST', \n",
    "                                                        number_of_ticks_per_quarter=500)\n",
    "\n",
    "  print('Done!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fkVqviDzJOrv"
   },
   "source": [
    "# (TRAIN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y9CBW8xYupH8"
   },
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "2moo7uUmpxvC"
   },
   "outputs": [],
   "source": [
    "#@title Train\n",
    "config = GPTConfig(VOCAB_SIZE, \n",
    "                   max_seq,\n",
    "                   dim_feedforward=dim_feedforward,\n",
    "                   n_layer=6, \n",
    "                   n_head=8, \n",
    "                   n_embd=512,\n",
    "                   enable_rpr=True,\n",
    "                   er_len=max_seq)\n",
    "model = GPT(config).to(get_device())\n",
    "\n",
    "#=====\n",
    "\n",
    "init_step = 0\n",
    "lr = LR_DEFAULT_START\n",
    "lr_stepper = LrStepTracker(d_model, SCHEDULER_WARMUP_STEPS, init_step)\n",
    "eval_loss_func = nn.CrossEntropyLoss(ignore_index=TOKEN_PAD)\n",
    "train_loss_func = eval_loss_func\n",
    "\n",
    "opt = Adam(model.parameters(), lr=lr, betas=(ADAM_BETA_1, ADAM_BETA_2), eps=ADAM_EPSILON)\n",
    "lr_scheduler = LambdaLR(opt, lr_stepper.step)\n",
    "\n",
    "\n",
    "#===\n",
    "\n",
    "best_eval_acc        = 0.0\n",
    "best_eval_acc_epoch  = -1\n",
    "best_eval_loss       = float(\"inf\")\n",
    "best_eval_loss_epoch = -1\n",
    "best_acc_file = '/notebooks/gpt2_rpr_acc.pth'\n",
    "best_loss_file = '/notebooks/gpt2_rpr_loss.pth'\n",
    "loss_train, loss_val, acc_val = [], [], []\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    new_best = False\n",
    "    \n",
    "    loss = train(epoch+1, model, train_loader, train_loss_func, opt, lr_scheduler, num_iters=-1)\n",
    "    loss_train.append(loss)\n",
    "    \n",
    "    eval_loss, eval_acc = eval_model(model, val_loader, eval_loss_func, num_iters=-1)\n",
    "    loss_val.append(eval_loss)\n",
    "    acc_val.append(eval_acc)\n",
    "    \n",
    "    if(eval_acc > best_eval_acc):\n",
    "        best_eval_acc = eval_acc\n",
    "        best_eval_acc_epoch  = epoch+1\n",
    "        torch.save(model.state_dict(), best_acc_file)\n",
    "        new_best = True\n",
    "\n",
    "    if(eval_loss < best_eval_loss):\n",
    "        best_eval_loss       = eval_loss\n",
    "        best_eval_loss_epoch = epoch+1\n",
    "        torch.save(model.state_dict(), best_loss_file)\n",
    "        new_best = True\n",
    "    \n",
    "    if(new_best):\n",
    "        print(\"Best eval acc epoch:\", best_eval_acc_epoch)\n",
    "        print(\"Best eval acc:\", best_eval_acc)\n",
    "        print(\"\")\n",
    "        print(\"Best eval loss epoch:\", best_eval_loss_epoch)\n",
    "        print(\"Best eval loss:\", best_eval_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "NNqmcFdRyC2M"
   },
   "outputs": [],
   "source": [
    "#@title Plot resulting training loss graph\n",
    "\n",
    "tr_loss_list = [item for sublist in loss_train for item in sublist]\n",
    "plt.plot([i for i in range(len(tr_loss_list))] ,tr_loss_list, 'b')\n",
    "plt.savefig('/notebooks/training-loss.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mdKFoeke9L7H"
   },
   "source": [
    "# (SAVE/LOAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "gqyDatHC9X1z"
   },
   "outputs": [],
   "source": [
    "#@title Save the model\n",
    "\n",
    "print('Saving the model...')\n",
    "full_path_to_model_checkpoint = \"/notebooks/TEST.pth\" #@param {type:\"string\"}\n",
    "torch.save(model.state_dict(), full_path_to_model_checkpoint)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "OaNkGcFo9UP_"
   },
   "outputs": [],
   "source": [
    "#@title Load/Reload the model\n",
    "full_path_to_model_checkpoint = \"/notebooks/TEST.pth\" #@param {type:\"string\"}\n",
    "\n",
    "print('Loading the model...')\n",
    "config = GPTConfig(VOCAB_SIZE, \n",
    "                   max_seq,\n",
    "                   dim_feedforward=dim_feedforward,\n",
    "                   n_layer=6, \n",
    "                   n_head=8, \n",
    "                   n_embd=512,\n",
    "                   enable_rpr=True,\n",
    "                   er_len=max_seq)\n",
    "\n",
    "model = GPT(config).to(get_device())\n",
    "\n",
    "model.load_state_dict(torch.load(full_path_to_model_checkpoint))\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom MIDI option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TMIDIX.Optimus_MIDI_TXT_Processor('/notebooks/custom.mid', dataset_MIDI_events_time_denominator=1, perfect_timings=True, musenet_encoding=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inputs = []\n",
    "pe = data[2][0]\n",
    "for S in data[2]:\n",
    "    inputs.extend([0])\n",
    "    if abs(S[1]-pe[1]) != 0 and abs(S[1]-pe[1]) < 376:\n",
    "\n",
    "        inputs.extend([abs(S[1]-pe[1])+10]) \n",
    "\n",
    "\n",
    "    o = S[4] // 12\n",
    "    t = S[4] % 12\n",
    "\n",
    "    for i in range(t+1):    \n",
    "                inputs.extend([o])\n",
    "    pe = S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UX1_5y5Fu8AH"
   },
   "source": [
    "# (GENERATE MUSIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Generate and download a MIDI file\n",
    "\n",
    "number_of_tokens_to_generate = 1024 #@param {type:\"slider\", min:8, max:1024, step:8}\n",
    "use_random_primer = False #@param {type:\"boolean\"}\n",
    "start_with_zero_token = False #@param {type:\"boolean\"}\n",
    "number_of_ticks_per_quarter = 500 #@param {type:\"slider\", min:50, max:1000, step:50}\n",
    "dataset_time_denominator = 10\n",
    "melody_conditioned_encoding = False\n",
    "encoding_has_MIDI_channels = False \n",
    "encoding_has_velocities = False\n",
    "simulate_velocity = True #@param {type:\"boolean\"}\n",
    "save_only_first_composition = True\n",
    "chars_encoding_offset_used_for_dataset = 33\n",
    "\n",
    "fname = '/notebooks/Optimus-VIRTUOSO-Composition'\n",
    "\n",
    "print('Optimus VIRTUOSO Model Generator')\n",
    "\n",
    "output_signature = 'Optimus VIRTUOSO'\n",
    "song_name = 'RGA Composition'\n",
    "\n",
    "model.eval()\n",
    "\n",
    "if use_random_primer:\n",
    "  sequence = [random.randint(10, 387) for i in range(64)]\n",
    "  idx = secrets.randbelow(len(sequence))\n",
    "  rand_seq = model.generate(torch.Tensor(sequence[idx:idx+120]), target_seq_length=number_of_tokens_to_generate)\n",
    "  out = rand_seq[0].cpu().numpy().tolist()\n",
    "\n",
    "else:\n",
    "  out = []\n",
    "  \n",
    "  try:\n",
    "    if start_with_zero_token:\n",
    "      rand_seq = model.generate(torch.Tensor(inputs), target_seq_length=number_of_tokens_to_generate)\n",
    "      out = rand_seq[0].cpu().numpy().tolist()\n",
    "    else:\n",
    "      idx = secrets.randbelow(len(train_data))\n",
    "      rand_seq = model.generate(torch.Tensor(train_data[idx:idx+120]), target_seq_length=number_of_tokens_to_generate)\n",
    "      out = rand_seq[0].cpu().numpy().tolist()\n",
    "  \n",
    "  except:\n",
    "    print('=' * 50)\n",
    "    print('Error! Try random priming instead!')\n",
    "    print('Shutting down...')\n",
    "    print('=' * 50)\n",
    "\n",
    "if len(out) != 0:\n",
    "  song = out\n",
    "  song_f = []\n",
    "  time = 0\n",
    "  octave = 0\n",
    "  tone = 0\n",
    "  pe = song[0]\n",
    "  for s in song:\n",
    "    \n",
    "    \n",
    "    if s > 0 and s < 10 and s != pe and pe < 10:\n",
    "\n",
    "        song_f.append(['note', time, 500, 0, (octave * 12) + tone, (octave * 10) + tone ])    \n",
    "        tone = 0\n",
    "        octave = s\n",
    "\n",
    "    if s > 9 and pe < 10 and pe >= 0:\n",
    "        song_f.append(['note', time, 500, 0, (octave * 12) + tone, (octave * 10) + tone ])\n",
    "        tone = 0\n",
    "\n",
    "        \n",
    "    if s > 9:\n",
    "        time += (s - 10)\n",
    "        tone = 0\n",
    "        \n",
    "    if s > 0 and s < 10:  \n",
    "       tone += 1\n",
    "       octave = s\n",
    "        \n",
    "\n",
    "        \n",
    "    pe = s\n",
    "\n",
    "  detailed_stats = TMIDIX.Tegridy_SONG_to_MIDI_Converter(song_f,\n",
    "                                                        output_signature = 'TEST',  \n",
    "                                                        output_file_name = '/notebooks/TEST', \n",
    "                                                        track_name='TEST', \n",
    "                                                        number_of_ticks_per_quarter=500)\n",
    "\n",
    "  print('Done!')    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Auto-Regressive Generator\n",
    "\n",
    "#@markdown NOTE: You much generate a seed composition first or it is not going to start\n",
    "\n",
    "number_of_cycles_to_run = 10 #@param {type:\"slider\", min:1, max:50, step:1}\n",
    "number_of_prime_tokens = 128 #@param {type:\"slider\", min:64, max:256, step:64}\n",
    "\n",
    "print('=' * 70)\n",
    "print('Optimus VIRTUOSO Auto-Regressive Model Generator')\n",
    "print('=' * 70)\n",
    "print('Starting up...')\n",
    "print('=' * 70)\n",
    "print('Prime length:', len(out))\n",
    "print('Prime tokens:', number_of_prime_tokens)\n",
    "print('Prime input sequence', out[-8:])\n",
    "\n",
    "if len(out) != 0:\n",
    "  print('=' * 70)\n",
    "  out_all = []\n",
    "  out_all.append(out)\n",
    "  for i in tqdm(range(number_of_cycles_to_run)):\n",
    "      rand_seq1 = model.generate(torch.Tensor(out[-number_of_prime_tokens:]), target_seq_length=1024)\n",
    "      out1 = rand_seq1[0].cpu().numpy().tolist()\n",
    "      out_all.append(out1[number_of_prime_tokens:])\n",
    "      out = out1[number_of_prime_tokens:]\n",
    "      \n",
    "      print(chr(10))\n",
    "      print('=' * 70)\n",
    "      print('Block number:', i+1)\n",
    "      print('Composition length so far:', (i+1) * 1024, 'notes')\n",
    "      print('=' * 70)\n",
    "\n",
    "  print('Done!' * 70)\n",
    "  print('Total blocks:', i+1)\n",
    "  print('Final omposition length:', (i+1) * 1024, 'notes')\n",
    "  print('=' * 70)\n",
    "  \n",
    "  out2 = []\n",
    "  for o in out_all:\n",
    "    out2.extend(o)\n",
    "    \n",
    "\n",
    "\n",
    "if len(out2) != 0:\n",
    "  song = out2\n",
    "  song_f = []\n",
    "  time = 0\n",
    "  octave = 0\n",
    "  tone = 0\n",
    "  pe = song[0]\n",
    "  for s in song:\n",
    "    \n",
    "    \n",
    "    if s > 0 and s < 10 and s != pe and pe < 10:\n",
    "\n",
    "        song_f.append(['note', time, 500, 0, (octave * 12) + tone, (octave * 10) + tone ])    \n",
    "        tone = 0\n",
    "        octave = s\n",
    "\n",
    "    if s > 9 and pe < 10 and pe >= 0:\n",
    "        song_f.append(['note', time, 500, 0, (octave * 12) + tone, (octave * 10) + tone ])\n",
    "        tone = 0\n",
    "\n",
    "        \n",
    "    if s > 9:\n",
    "        time += (s - 10)\n",
    "        tone = 0\n",
    "        \n",
    "    if s > 0 and s < 10:  \n",
    "       tone += 1\n",
    "       octave = s\n",
    "        \n",
    "\n",
    "        \n",
    "    pe = s\n",
    "\n",
    "  detailed_stats = TMIDIX.Tegridy_SONG_to_MIDI_Converter(song_f,\n",
    "                                                        output_signature = 'TEST',  \n",
    "                                                        output_file_name = '/notebooks/TEST', \n",
    "                                                        track_name='TEST', \n",
    "                                                        number_of_ticks_per_quarter=500)\n",
    "\n",
    "  print('Done!')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('=' * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YzCMd94Tu_gz"
   },
   "source": [
    "# Congrats! You did it! :)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Optimus_VIRTUOSO_Multi_Instrumental_RGA_Edition.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
